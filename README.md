1. Veille sur le MLaaS et l'AutoML
Nous devons faire une recherche concise sur les sujets suivants :
    • AutoML et ses avantages
    • MLaaS et ses avantages
    • Google Cloud Platform et Vertex AI
    • AWS et SageMaker
    • Azure et Azure Machine Learning
    • DataRobot
Pour cette partie, nous allons réaliser des recherches en ligne et résumer les informations dans un rapport structuré.
2. Analyse de sentiments avec AutoML
Pré-traitement des données
Nous utiliserons les fichiers sentiment_analysis_emotions_train.csv et sentiment_analysis_emotions_test.csv pour cette tâche. Les étapes incluent :
    • Chargement des données
    • Nettoyage des données (gestion des valeurs manquantes, normalisation, etc.)
    • Exploration des données pour comprendre leur structure et distribution
Visualisation des données
Créer des visualisations pour explorer les données, notamment des histogrammes, des nuages de mots, etc., pour les données textuelles.
Entraînement des modèles
Utilisation de PyCaret pour entraîner plusieurs modèles de classification multi-classes. Les étapes incluent :
    • Installation et importation de PyCaret
    • Initialisation de l'environnement de PyCaret pour la classification
    • Entraînement de différents modèles
    • Comparaison des modèles selon différentes métriques (précision, rappel, F1-score, etc.)
3. Déploiement sur une plateforme MLaaS
Tester l'un des services MLaaS suivants en utilisant les versions d'essai gratuites :
    • Google Cloud Platform avec Vertex AI
    • AWS avec SageMaker
    • Azure avec Azure Machine Learning
    • DataRobot
Les étapes incluent :
    • Déploiement du modèle d'analyse de sentiment
    • Documentation des étapes de construction, déploiement et monitoring avec des captures d'écran ou des scripts
4. Présentation et Repository GitHub
Présentation
Préparer une présentation explicative sous forme de diapositives, incluant :
    • La réflexion derrière le travail
    • L'organisation sur Trello (ou tout autre outil de gestion de projet)
    • Les captures d'écran des différentes étapes
Repository GitHub
Créer un repository public nommé ml-in-the-clouds contenant :
    • Un notebook Jupyter propre et commenté pour le développement de l'outil, du prétraitement à la modélisation
    • Un fichier README.md décrivant le contexte du projet, les données, les outils utilisés et une conclusion
Plan d'action détaillé
    1. Recherche et veille technologique
        ◦ Effectuer une recherche sur les sujets indiqués et rédiger un rapport détaillé.
        ◦ Prochaine étape : Rédiger le rapport de veille technologique.
    2. Pré-traitement et analyse exploratoire des données
        ◦ Charger et nettoyer les fichiers de données d'entraînement et de test.
        ◦ Prochaine étape : Effectuer une analyse exploratoire et créer des visualisations.
    3. Entraînement et comparaison des modèles
        ◦ Utiliser PyCaret pour entraîner plusieurs modèles de classification multi-classes.
        ◦ Prochaine étape : Initialiser l'environnement PyCaret et entraîner les modèles.
    4. Déploiement sur une plateforme MLaaS
        ◦ Choisir une plateforme MLaaS et déployer le modèle.
        ◦ Prochaine étape : Documenter chaque étape avec des captures d'écran ou des scripts.
    5. Création de la présentation et du repository GitHub
        ◦ Préparer la présentation explicative et créer le repository GitHub.
        ◦ Prochaine étape : Rédiger le notebook Jupyter et le fichier README.md.
